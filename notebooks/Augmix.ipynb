{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsrsBlO49booErOQ0isbMr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tannisthamaiti/DiffusionModels_DDPM_DDIM/blob/main/Augmix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rslnsgPXoR-7"
      },
      "outputs": [],
      "source": [
        "# AugMix Implementation in PyTorch\n",
        "# Source: Hendrycks et al. \"AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty.\" ICLR 2020.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- AugMix Utils ---\n",
        "def int_parameter(level, maxval):\n",
        "    return int(level * maxval / 10)\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "    return float(level) * maxval / 10.\n",
        "\n",
        "def sample_level(n):\n",
        "    return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "def autocontrast(img):\n",
        "    return Image.fromarray(np.array(img)).convert(\"RGB\")\n",
        "\n",
        "def rotate(img, level):\n",
        "    return img.rotate(int_parameter(level, 30))\n",
        "\n",
        "def shear_x(img, level):\n",
        "    return img.transform(img.size, Image.AFFINE, (1, float_parameter(level, 0.3), 0, 0, 1, 0))\n",
        "\n",
        "def shear_y(img, level):\n",
        "    return img.transform(img.size, Image.AFFINE, (1, 0, 0, float_parameter(level, 0.3), 1, 0))\n",
        "\n",
        "augmentations = [\n",
        "    lambda x: x,\n",
        "    autocontrast,\n",
        "    lambda x: rotate(x, sample_level(3)),\n",
        "    lambda x: shear_x(x, sample_level(3)),\n",
        "    lambda x: shear_y(x, sample_level(3)),\n",
        "]\n",
        "\n",
        "def augmix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
        "    ws = np.float32(np.random.dirichlet([alpha] * width))\n",
        "    m = np.float32(np.random.beta(alpha, alpha))\n",
        "\n",
        "    mix = torch.zeros_like(T.ToTensor()(image))\n",
        "    for i in range(width):\n",
        "        image_aug = image.copy()\n",
        "        d = depth if depth > 0 else np.random.randint(1, 4)\n",
        "        for _ in range(d):\n",
        "            op = random.choice(augmentations)\n",
        "            image_aug = op(image_aug)\n",
        "        mix += ws[i] * T.ToTensor()(image_aug)\n",
        "\n",
        "    mixed = (1 - m) * T.ToTensor()(image) + m * mix\n",
        "    return mixed\n",
        "\n",
        "# --- Dataset Setup ---\n",
        "transform_base = T.Compose([\n",
        "    T.Resize(32),\n",
        "    T.CenterCrop(32),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_base)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# --- Model Setup ---\n",
        "model = models.resnet18(pretrained=False, num_classes=10).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "def jsd_loss(p_clean, p_aug1, p_aug2):\n",
        "    p_mixture = (p_clean + p_aug1 + p_aug2) / 3.\n",
        "    p_mixture = torch.clamp(p_mixture, 1e-7, 1).log()\n",
        "    return (F.kl_div(p_mixture, p_clean, reduction='batchmean') +\n",
        "            F.kl_div(p_mixture, p_aug1, reduction='batchmean') +\n",
        "            F.kl_div(p_mixture, p_aug2, reduction='batchmean')) / 3.\n",
        "\n",
        "# --- Training Loop (1 Epoch for Demonstration) ---\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.train()\n",
        "\n",
        "for images, labels in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    clean = images\n",
        "    aug1 = torch.stack([augmix(img) for img in images.cpu()]).to(device)\n",
        "    aug2 = torch.stack([augmix(img) for img in images.cpu()]).to(device)\n",
        "\n",
        "    logits_clean = model(clean)\n",
        "    logits_aug1 = model(aug1)\n",
        "    logits_aug2 = model(aug2)\n",
        "\n",
        "    loss_ce = F.cross_entropy(logits_clean, labels)\n",
        "    loss_jsd = jsd_loss(F.softmax(logits_clean, dim=1),\n",
        "                        F.softmax(logits_aug1, dim=1),\n",
        "                        F.softmax(logits_aug2, dim=1))\n",
        "    loss = loss_ce + 12 * loss_jsd\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    break  # remove this to train for full epoch\n",
        "\n",
        "print(\"AugMix training step completed.\")\n",
        "\n",
        "# --- Citation ---\n",
        "print(\"\"\"\n",
        "@inproceedings{hendrycks2020augmix,\n",
        "  title={AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty},\n",
        "  author={Hendrycks, Dan and Mu, Norman and Cubuk, Ekin D and Zoph, Barret and Gilmer, Justin and Lakshminarayanan, Balaji},\n",
        "  booktitle={International Conference on Learning Representations (ICLR)},\n",
        "  year={2020}\n",
        "}\n",
        "\"\"\")\n"
      ]
    }
  ]
}